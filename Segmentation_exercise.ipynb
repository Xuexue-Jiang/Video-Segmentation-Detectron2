{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Segmented videos\n",
        "https://drive.google.com/drive/folders/166kfA9u-fuhLOAkILBetone0gr2t7SVX?usp=sharing\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cDLJzhIT3Jgl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII"
      },
      "source": [
        "# Install detectron2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_FzH13EjseR"
      },
      "outputs": [],
      "source": [
        "# install dependencies: \n",
        "!pip install pyyaml==5.1\n",
        "\n",
        "# check pytorch installation: \n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUmK767kWQlq"
      },
      "outputs": [],
      "source": [
        "# clone the repo in order to access pre-defined configs in PointRend project\n",
        "!git clone --branch v0.6 https://github.com/facebookresearch/detectron2.git detectron2_repo\n",
        "\n",
        "# install detectron2 from source\n",
        "!pip install -e detectron2_repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "outputs": [],
      "source": [
        "# Restart runtime prior to this, to let the installation take effect\n",
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import cv2\n",
        "import torch\n",
        "import time\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.video_visualizer import VideoVisualizer\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "from detectron2.data import MetadataCatalog\n",
        "coco_metadata = MetadataCatalog.get(\"coco_2017_val\")\n",
        "\n",
        "# import PointRend project\n",
        "from detectron2.projects import point_rend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dq9GY37ml1kr"
      },
      "outputs": [],
      "source": [
        "# Extract video properties\n",
        "video = cv2.VideoCapture('close.mp4')\n",
        "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "frames_per_second = video.get(cv2.CAP_PROP_FPS)\n",
        "num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "\n",
        "# Initialize video writer\n",
        "video_writer = cv2.VideoWriter('close_segmented.mp4', fourcc=cv2.VideoWriter_fourcc(*\"mp4v\"), fps=float(frames_per_second), frameSize=(width, height), isColor=True)\n",
        "\n",
        "\n",
        "# Initialize predictor\n",
        "cfg = get_cfg()\n",
        "# Add PointRend-specific config\n",
        "point_rend.add_pointrend_config(cfg)\n",
        "# Load a config from file\n",
        "cfg.merge_from_file(\"detectron2_repo/projects/PointRend/configs/InstanceSegmentation/pointrend_rcnn_R_50_FPN_3x_coco.yaml\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # set threshold for this model\n",
        "# Use a model from PointRend model zoo: https://github.com/facebookresearch/detectron2/tree/master/projects/PointRend#pretrained-models\n",
        "cfg.MODEL.WEIGHTS = \"detectron2://PointRend/InstanceSegmentation/pointrend_rcnn_R_50_FPN_3x_coco/164955410/model_final_edd263.pkl\"\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "\n",
        "# Initialize visualizer\n",
        "v = VideoVisualizer(MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), ColorMode.IMAGE)\n",
        "\n",
        "\n",
        "\n",
        "def runOnVideo(video, maxFrames):\n",
        "    \"\"\" Runs the predictor on every frame in the video (unless maxFrames is given),\n",
        "    and returns the frame with the predictions drawn.\n",
        "    \"\"\"\n",
        "\n",
        "    readFrames = 0\n",
        "    while True:\n",
        "        hasFrame, frame = video.read()\n",
        "        if not hasFrame:\n",
        "            break\n",
        "\n",
        "        # Get prediction results for this frame\n",
        "        outputs = predictor(frame)\n",
        "\n",
        "\n",
        "        # Make sure the frame is colored\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "\n",
        "        # Draw a visualization of the predictions using the video visualizer on the person class\n",
        "        visualization = v.draw_instance_predictions(frame, outputs[\"instances\"][outputs['instances'].pred_classes == 0].to(\"cpu\"))\n",
        "\n",
        "\n",
        "        # Convert Matplotlib RGB format to OpenCV BGR format\n",
        "        visualization = cv2.cvtColor(visualization.get_image(), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        yield visualization\n",
        "\n",
        "        readFrames += 1\n",
        "        if readFrames > maxFrames:\n",
        "            break\n",
        "\n",
        "# Create a cut-off for debugging\n",
        "num_frames = 1000\n",
        "\n",
        "# Enumerate the frames of the video\n",
        "for visualization in tqdm.tqdm(runOnVideo(video, num_frames), total=num_frames):\n",
        "\n",
        "    # Write to video file\n",
        "    video_writer.write(visualization)\n",
        "\n",
        "# Release resources\n",
        "video.release()\n",
        "video_writer.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Segmentation_exercise.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}